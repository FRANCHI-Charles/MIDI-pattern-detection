{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f0ad4e",
   "metadata": {},
   "source": [
    "# First test of PatternLearner network on Fugues Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6320f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from Fugues_data.loader import FuguesDataset\n",
    "from ML.architecture import PatternLearner, CorrelationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cf479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"Fugues_data\", \"data_16_reduced.pkl\")\n",
    "TEST_SIZE = 0.1\n",
    "VALIDATION_SIZE = 0.2\n",
    "CNN_MODEL_NAME = 'cnn_patterns_'\n",
    "\n",
    "MAX_EPOCH = 200\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.1\n",
    "EPSILON = 0.0000001\n",
    "PATTERNS_MAXSIZE = (1, 4*16, 10)\n",
    "PATIENCE = 3\n",
    "REFINEMENT = 3  # restart training after patience runs out with the best model, decrease lr by...\n",
    "LR_FAC = 0.1    # ... the learning rate factor lr_fac: lr_new = lr_old*lr_fac\n",
    "LOG_INTERVAL = 60  # seconds\n",
    "\n",
    "MINDIV = 16 #from Fugues_data.midi_to_pkl import MINDIV\n",
    "\n",
    "torch.manual_seed(689)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3d63f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee47fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([210, 1, 7712, 60])\n"
     ]
    }
   ],
   "source": [
    "data = FuguesDataset(DATA_PATH)\n",
    "print(data[:].shape)\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if torch.cuda.is_available() else {'num_workers': 0}\n",
    "train, validation, test_data = random_split(data, [(1-TEST_SIZE) * (1-VALIDATION_SIZE), (1-TEST_SIZE) * VALIDATION_SIZE, TEST_SIZE])\n",
    "valid_data = next(iter(DataLoader(validation, len(validation), **kwargs))).float().to(device)\n",
    "train_loader = DataLoader(train, BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_data = next(iter(DataLoader(test_data, len(test_data), **kwargs))).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57c9d2",
   "metadata": {},
   "source": [
    "Each music file is nearly equivalent to a picture of size 1000x500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc3e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 7712, 60])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4dd6b",
   "metadata": {},
   "source": [
    "## Load architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc91610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after conv 1 : torch.Size([2, 3, 964, 60])\n",
      "Shape after conv 2 : torch.Size([2, 6, 120, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after conv 3 : torch.Size([2, 12, 15, 60])\n",
      "Shape after conv 4 : torch.Size([2, 24, 1, 6])\n",
      "Shape after dense Layer : torch.Size([2, 640])\n",
      "torch.Size([2, 1, 64, 10])\n",
      "Number of parameters: 177137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "model = PatternLearner(data[0].shape, PATTERNS_MAXSIZE)\n",
    "\n",
    "test = torch.rand((2, *data[0].shape))\n",
    "print(model(test, True).shape)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a1183",
   "metadata": {},
   "source": [
    "## Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a613f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = Adam\n",
    "LOSS_FUNCTION = CorrelationLoss().minmax_regul(beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0730bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_cnn(model, optimizer):\n",
    "    \"\"\"\n",
    "    Training loop for one epoch of NN training.\n",
    "    \"\"\"\n",
    "    model.train()  # set model to training mode (activate dropout layers if any)\n",
    "    t = time() # we measure the needed time\n",
    "    for batch_idx, input_data in enumerate(train_loader):  # iterate over training input_data\n",
    "        input_data = input_data.float().to(device)  # move input_data to device (GPU) if necessary\n",
    "        optimizer.zero_grad()  # reset optimizer\n",
    "        output = model(input_data)   # forward pass: calculate output of network for input_data\n",
    "        loss = LOSS_FUNCTION(output, input_data)\n",
    "\n",
    "        loss.backward()  # backward pass: calculate gradients using automatic diff. and backprop.\n",
    "        optimizer.step()  # udpate parameters of network using our optimizer\n",
    "        cur_time = time()\n",
    "        # print some outputs if we reached our logging interval\n",
    "        if cur_time - t > LOG_INTERVAL or batch_idx == len(train_loader)-1:  \n",
    "            print(f\"[{batch_idx * len(input_data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\",\n",
    "                  f\"\\tloss: {loss.item():.6f}, took {cur_time - t:.2f}s\")\n",
    "            t = cur_time\n",
    "\n",
    "\n",
    "def valid_cnn(model):\n",
    "    \"\"\"\n",
    "    Test loss evaluation\n",
    "    \"\"\"\n",
    "    model.eval()  # set model to inference mode (deactivate dropout layers)\n",
    "    with torch.no_grad():  # do not calculate gradients since we do not want to do updates\n",
    "        output = model(test_data)\n",
    "        loss = LOSS_FUNCTION(output, test_data)\n",
    "    print(f'Average eval loss: {loss:.4f}\\n')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9cb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn():\n",
    "    \"\"\"\n",
    "    Run CNN training using the datasets.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "        nn.Model\n",
    "            trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # create model and optimizer, we use plain SGD with momentum\n",
    "    optimizer = OPTIMIZER(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    model_cnt = 0\n",
    "    new_model_file = os.path.join(CNN_MODEL_NAME + str(model_cnt) + '.model')\n",
    "    while os.path.exists(new_model_file):\n",
    "        model_cnt += 1\n",
    "        new_model_file = os.path.join(CNN_MODEL_NAME + str(model_cnt) + '.model')\n",
    "    \n",
    "\n",
    "    # train model for max_epochs epochs, output loss after log_intervall seconds.\n",
    "    # for each epoch run once on validation set, \n",
    "    # write model to disk if validation loss decreased\n",
    "    # if validation loss increased, check for early stopping with patience and refinements\n",
    "    # after model is trained, perform a run on test set and output loss (don't forget to reload best model!)\n",
    "    best_valid_loss = 9999.\n",
    "    cur_patience = PATIENCE\n",
    "    cur_refin = REFINEMENT\n",
    "\n",
    "    #model.load_state_dict(torch.load(last_model_file, map_location=device).state_dict())\n",
    "    print('Training CNN...')\n",
    "    start_t = time()\n",
    "\n",
    "    for epoch in range(1, MAX_EPOCH+1):\n",
    "        train_epoch_cnn(model, optimizer)\n",
    "        valid_loss = valid_cnn(model)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model, new_model_file)\n",
    "            best_valid_loss = valid_loss\n",
    "            cur_patience = PATIENCE\n",
    "\n",
    "        elif cur_patience <=0:\n",
    "            model.load_state_dict(torch.load(new_model_file, map_location=device).state_dict())\n",
    "            if cur_refin <= 0:\n",
    "                print(\"Max refinement reached !\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Max patience reached !\")\n",
    "                \n",
    "                cur_patience = PATIENCE\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = LR_FAC * param_group['lr']\n",
    "                    param_group['lr'] = lr\n",
    "                cur_refin -= 1\n",
    "            \n",
    "        else:\n",
    "            print(\"We still have patience...\")\n",
    "            cur_patience -= 1\n",
    "    \n",
    "    print(f'Training took: {time()-start_t:.2f}s for {epoch} epochs')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_cnn(load_model:str):\n",
    "    \"Load the model.\"\n",
    "    if load_model is None or not os.path.exists(load_model):\n",
    "        print('Model file not found, unable to load...')\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(load_model, map_location=device).state_dict())\n",
    "        print(\"Model file loaded: {}\".format(load_model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9ba0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 7712, 60])\n",
      "torch.Size([2, 1, 64, 10])\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7712) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m# reset optimizer\u001b[39;00m\n\u001b[32m      5\u001b[39m output = model(input_data)   \u001b[38;5;66;03m# forward pass: calculate output of network for input_data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m loss = \u001b[43mLOSS_FUNCTION\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m loss.backward()  \u001b[38;5;66;03m# backward pass: calculate gradients using automatic diff. and backprop.\u001b[39;00m\n\u001b[32m      9\u001b[39m optimizer.step()  \u001b[38;5;66;03m# udpate parameters of network using our optimizer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Intership 2025/Code/MIDI-pattern-detection/ML/architecture.py:63\u001b[39m, in \u001b[36mCorrelationLoss.minmax_regul.<locals>.loss\u001b[39m\u001b[34m(output, input)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss\u001b[39m(output:torch.Tensor, \u001b[38;5;28minput\u001b[39m:torch.Tensor):\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m    output : the output patterns of dimension (OutChannels, Channel//groups, H, W)\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    input : the original image to correlate with.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     added_cor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_added_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     difference_term, normalisation = \u001b[38;5;28mself\u001b[39m._gamma_regul(output)\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -(\u001b[32m1000\u001b[39m*added_cor/\u001b[38;5;28minput\u001b[39m.sum() - \u001b[38;5;28mself\u001b[39m.beta * output.sum()/math.prod(output.shape) + \u001b[38;5;28mself\u001b[39m.gamma * difference_term /normalisation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Intership 2025/Code/MIDI-pattern-detection/ML/architecture.py:178\u001b[39m, in \u001b[36mCorrelationLoss._added_correlation\u001b[39m\u001b[34m(self, output, input)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output.shape) !=\u001b[32m4\u001b[39m:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33moutput must be of dimension (OutChannels, Channel//groups, H, W)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m cor = \u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m added_cor = \u001b[38;5;28mself\u001b[39m.smooth_function(cor).sum()\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m added_cor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Intership 2025/Code/MIDI-pattern-detection/ML/utils.py:184\u001b[39m, in \u001b[36mcorrelation\u001b[39m\u001b[34m(ar, selem, device, convdim, return_numpy_array)\u001b[39m\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mprint\u001b[39m(selem.shape)\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mprint\u001b[39m(selem.sum((-\u001b[32m2\u001b[39m,-\u001b[32m1\u001b[39m)).shape)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     torch_array = \u001b[43mconv_results\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mselem\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_numpy_array:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_array.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m).int().numpy()\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (7712) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "optimizer = OPTIMIZER(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "input_data = valid_data[:2].float().to(device)  # move input_data to device (GPU) if necessary\n",
    "optimizer.zero_grad()  # reset optimizer\n",
    "output = model(input_data)   # forward pass: calculate output of network for input_data\n",
    "loss = LOSS_FUNCTION(output, input_data)\n",
    "\n",
    "loss.backward()  # backward pass: calculate gradients using automatic diff. and backprop.\n",
    "optimizer.step()  # udpate parameters of network using our optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537786cc",
   "metadata": {},
   "source": [
    "PROBLEM: Le kernel créé pour chaque image est caculé sur toutes les images, ce qui change les dimensions. Dois modifier erodila !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
