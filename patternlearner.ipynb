{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f0ad4e",
   "metadata": {},
   "source": [
    "# First test of PatternLearner network on Fugues Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6320f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from Fugues_data.loader import FuguesDataset\n",
    "from ML.architecture import PatternLearner, CorrelationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cf479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"Fugues_data\", \"data_16_reduced.pkl\")\n",
    "TEST_SIZE = 0.1\n",
    "VALIDATION_SIZE = 0.2\n",
    "CNN_MODEL_NAME = 'cnn_patterns_'\n",
    "\n",
    "MAX_EPOCH = 200\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.1\n",
    "EPSILON = 0.0000001\n",
    "PATTERNS_MAXSIZE = (1, 4*16, 10)\n",
    "PATIENCE = 3\n",
    "REFINEMENT = 3  # restart training after patience runs out with the best model, decrease lr by...\n",
    "LR_FAC = 0.1    # ... the learning rate factor lr_fac: lr_new = lr_old*lr_fac\n",
    "LOG_INTERVAL = 60  # seconds\n",
    "\n",
    "MINDIV = 16 #from Fugues_data.midi_to_pkl import MINDIV\n",
    "\n",
    "torch.manual_seed(689)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3d63f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee47fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([210, 1, 7712, 60])\n"
     ]
    }
   ],
   "source": [
    "data = FuguesDataset(DATA_PATH)\n",
    "print(data[:].shape)\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if torch.cuda.is_available() else {'num_workers': 0}\n",
    "train, validation, test_data = random_split(data, [(1-TEST_SIZE) * (1-VALIDATION_SIZE), (1-TEST_SIZE) * VALIDATION_SIZE, TEST_SIZE])\n",
    "valid_data = next(iter(DataLoader(validation, len(validation), **kwargs))).float().to(device)\n",
    "train_loader = DataLoader(train, BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_data = next(iter(DataLoader(test_data, len(test_data), **kwargs))).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57c9d2",
   "metadata": {},
   "source": [
    "Each music file is nearly equivalent to a picture of size 1000x500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc3e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 7712, 60])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4dd6b",
   "metadata": {},
   "source": [
    "## Load architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc91610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after conv 1 : torch.Size([2, 3, 964, 60])\n",
      "Shape after conv 2 : torch.Size([2, 6, 120, 60])\n",
      "Shape after conv 3 : torch.Size([2, 12, 15, 60])\n",
      "Shape after conv 4 : torch.Size([2, 24, 1, 6])\n",
      "Shape after dense Layer : torch.Size([2, 640])\n",
      "torch.Size([2, 1, 64, 10])\n",
      "Number of parameters: 177137\n"
     ]
    }
   ],
   "source": [
    "model = PatternLearner(data[0].shape, PATTERNS_MAXSIZE)\n",
    "\n",
    "test = torch.rand((2, *data[0].shape))\n",
    "print(model(test, True).shape)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a1183",
   "metadata": {},
   "source": [
    "## Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a613f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = Adam\n",
    "LOSS_FUNCTION = CorrelationLoss().minmax_regul(beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_cnn(model, optimizer):\n",
    "    \"\"\"\n",
    "    Training loop for one epoch of NN training.\n",
    "    \"\"\"\n",
    "    model.train()  # set model to training mode (activate dropout layers if any)\n",
    "    t = time() # we measure the needed time\n",
    "    for batch_idx, input_data in enumerate(train_loader):  # iterate over training input_data\n",
    "        input_data = input_data.float().to(device)  # move input_data to device (GPU) if necessary\n",
    "        optimizer.zero_grad()  # reset optimizer\n",
    "        output = model(input_data)   # forward pass: calculate output of network for input_data\n",
    "        loss = LOSS_FUNCTION(output, input_data)\n",
    "\n",
    "        loss.backward()  # backward pass: calculate gradients using automatic diff. and backprop.\n",
    "        optimizer.step()  # udpate parameters of network using our optimizer\n",
    "        cur_time = time()\n",
    "        # print some outputs if we reached our logging interval\n",
    "        if cur_time - t > LOG_INTERVAL or batch_idx == len(train_loader)-1:  \n",
    "            print(f\"[{batch_idx * BATCH_SIZE}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\",\n",
    "                  f\"\\tloss: {loss.item():.6f}, took {cur_time - t:.2f}s\")\n",
    "            t = cur_time\n",
    "\n",
    "\n",
    "def valid_cnn(model):\n",
    "    \"\"\"\n",
    "    Test loss evaluation\n",
    "    \"\"\"\n",
    "    model.eval()  # set model to inference mode (deactivate dropout layers)\n",
    "    with torch.no_grad():  # do not calculate gradients since we do not want to do updates\n",
    "        output = model(test_data)\n",
    "        loss = LOSS_FUNCTION(output, test_data)\n",
    "    print(f'Average eval loss: {loss:.4f}\\n')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9cb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn():\n",
    "    \"\"\"\n",
    "    Run CNN training using the datasets.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "        nn.Model\n",
    "            trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # create model and optimizer, we use plain SGD with momentum\n",
    "    optimizer = OPTIMIZER(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    model_cnt = 0\n",
    "    new_model_file = os.path.join(CNN_MODEL_NAME + str(model_cnt) + '.model')\n",
    "    while os.path.exists(new_model_file):\n",
    "        model_cnt += 1\n",
    "        new_model_file = os.path.join(CNN_MODEL_NAME + str(model_cnt) + '.model')\n",
    "    \n",
    "\n",
    "    # train model for max_epochs epochs, output loss after log_intervall seconds.\n",
    "    # for each epoch run once on validation set, \n",
    "    # write model to disk if validation loss decreased\n",
    "    # if validation loss increased, check for early stopping with patience and refinements\n",
    "    # after model is trained, perform a run on test set and output loss (don't forget to reload best model!)\n",
    "    best_valid_loss = 9999.\n",
    "    cur_patience = PATIENCE\n",
    "    cur_refin = REFINEMENT\n",
    "\n",
    "    #model.load_state_dict(torch.load(last_model_file, map_location=device).state_dict())\n",
    "    print('Training CNN...')\n",
    "    start_t = time()\n",
    "\n",
    "    for epoch in range(1, MAX_EPOCH+1):\n",
    "        train_epoch_cnn(model, optimizer)\n",
    "        valid_loss = valid_cnn(model)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model, new_model_file)\n",
    "            best_valid_loss = valid_loss\n",
    "            cur_patience = PATIENCE\n",
    "\n",
    "        elif cur_patience <=0:\n",
    "            model.load_state_dict(torch.load(new_model_file, map_location=device).state_dict())\n",
    "            if cur_refin <= 0:\n",
    "                print(\"Max refinement reached !\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Max patience reached !\")\n",
    "                \n",
    "                cur_patience = PATIENCE\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = LR_FAC * param_group['lr']\n",
    "                    param_group['lr'] = lr\n",
    "                cur_refin -= 1\n",
    "            \n",
    "        else:\n",
    "            print(\"We still have patience...\")\n",
    "            cur_patience -= 1\n",
    "    \n",
    "    print(f'Training took: {time()-start_t:.2f}s for {epoch} epochs')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def load_cnn(load_model:str):\n",
    "    \"Load the model.\"\n",
    "    if load_model is None or not os.path.exists(load_model):\n",
    "        print('Model file not found, unable to load...')\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(load_model, map_location=device).state_dict())\n",
    "        print(\"Model file loaded: {}\".format(load_model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9ba0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN...\n",
      "[50/152 (31%)] \tloss: -0.220237, took 67.17s\n",
      "[110/152 (69%)] \tloss: -0.197817, took 62.34s\n",
      "[30/152 (94%)] \tloss: -0.165877, took 33.72s\n",
      "Average eval loss: -0.2128\n",
      "\n",
      "[50/152 (31%)] \tloss: -0.215598, took 63.18s\n",
      "[110/152 (69%)] \tloss: -0.236806, took 62.11s\n",
      "[30/152 (94%)] \tloss: -0.200092, took 37.48s\n",
      "Average eval loss: -0.2101\n",
      "\n",
      "We still have patience...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtrain_cnn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     32\u001b[39m start_t = time()\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, MAX_EPOCH+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mtrain_epoch_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     valid_loss = valid_cnn(model)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss < best_valid_loss:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_epoch_cnn\u001b[39m\u001b[34m(model, optimizer)\u001b[39m\n\u001b[32m     10\u001b[39m output = model(input_data)   \u001b[38;5;66;03m# forward pass: calculate output of network for input_data\u001b[39;00m\n\u001b[32m     11\u001b[39m loss = LOSS_FUNCTION(output, input_data)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# backward pass: calculate gradients using automatic diff. and backprop.\u001b[39;00m\n\u001b[32m     14\u001b[39m optimizer.step()  \u001b[38;5;66;03m# udpate parameters of network using our optimizer\u001b[39;00m\n\u001b[32m     15\u001b[39m cur_time = time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/IS2025/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    517\u001b[39m         Tensor.backward,\n\u001b[32m    518\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         inputs=inputs,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/IS2025/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    262\u001b[39m     retain_graph = create_graph\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/IS2025/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_cnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
